<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/png" href="/favicon.png" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lit Audio UI</title>
    <!-- Material Symbols for icons -->
    <link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" rel="stylesheet" />
    <style>
      :root {
        font-family: Inter, system-ui, Avenir, Helvetica, Arial, sans-serif;
        color-scheme: light dark;
      }
      body {
        margin: 0;
        padding: 2rem;
        background-color: #f5f5f5;
      }
      @media (prefers-color-scheme: dark) {
        body {
          background-color: #121212;
          color: white;
        }
      }
      .demo-container {
        max-width: 800px;
        margin: 0 auto;
        display: flex;
        flex-direction: column;
        gap: 2rem;
      }
      .component-card {
        background: var(--md-sys-color-surface, #ffffff);
        color: var(--md-sys-color-on-surface, #1e1e1e);
        border-radius: 12px;
        padding: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      }
      @media (prefers-color-scheme: dark) {
        .component-card {
          background: #1e1e1e;
          color: white;
        }
      }
      .component-title {
        margin-top: 0;
        margin-bottom: 1rem;
        font-size: 1.2rem;
        font-weight: 600;
        border-bottom: 1px solid #ccc;
        padding-bottom: 0.5rem;
      }
      
      .control-panel {
        display: flex;
        gap: 1rem;
        margin-bottom: 1rem;
        align-items: center;
      }
      
      .waveform-container {
        margin-top: 1rem;
        padding: 1rem;
        background: #f0f0f0;
        border-radius: 8px;
        height: 120px;
      }
      
      @media (prefers-color-scheme: dark) {
        .waveform-container {
          background: #2a2a2a;
        }
      }
    </style>
  </head>
  <body>
    <div class="demo-container">
      <h1>Lit Audio UI Components</h1>
      <p>A pure Lit WebComponents library for audio visualization and control.</p>
      
      <!-- Static Waveform Demo -->
      <div class="component-card">
        <h2 class="component-title">sui-waveform (Static Timeline)</h2>
        <p>A pre-computed scrubbable waveform. This generates a random mock array of 200 data points (0.0 to 1.0) and visualizes them instantly.</p>
        
        <div class="waveform-container" style="height: 64px;">
          <sui-waveform id="demo-static-waveform" height="64" barColor="var(--md-sys-color-primary, #0066cc)" fadeEdges="true"></sui-waveform>
        </div>
      </div>
      
      <!-- Live Waveform Demo -->
      <div class="component-card">
        <h2 class="component-title">sui-live-waveform (Real-time Audio)</h2>
        <p>A live visualizer that responds to an active <code>AudioContext</code>. Click "Play Sample" to feed the <strong>Gemini TTS</strong> speech sample into the visualizer.</p>
        
        <div class="control-panel">
          <audio id="demo-audio-player" src="/samples/speech_sample-Aoede-20260212-183352.wav" preload="metadata" controls></audio>
          
          <div style="flex: 1"></div>
          
          <button id="btn-processing" style="padding: 8px 16px; border-radius: 4px; border: 1px solid #ccc; cursor: pointer;">
            Toggle "Processing" State
          </button>
        </div>
        
        <div class="waveform-container" style="height: 100px; display: flex; align-items: center;">
           <sui-live-waveform id="demo-live-waveform" height="80" sensitivity="2.5" barColor="var(--md-sys-color-primary, #0066cc)"></sui-live-waveform>
        </div>
      </div>

      <!-- Audio Player Demo -->
      <div class="component-card">
        <h2 class="component-title">sui-audio-player</h2>
        <p>A highly polished, customized audio player utilizing Material Web Components under the hood.</p>
        
        <div style="margin-top: 1rem;">
          <sui-audio-player id="demo-player"></sui-audio-player>
        </div>
      </div>

      <!-- Voice Button Demo -->
      <div class="component-card">
        <h2 class="component-title">sui-voice-button</h2>
        <p>A compound interactive button that dynamically mounts the live visualizer depending on its state. Click to cycle through the states: Idle -> Recording -> Processing -> Success -> Error.</p>
        
        <div style="margin-top: 1rem; display: flex; gap: 1rem; align-items: center;">
          <sui-voice-button id="demo-voice-btn" state="idle" label="Start Recording" trailing="âŒ¥Space"></sui-voice-button>
          
          <span id="demo-voice-btn-state" style="font-family: monospace; font-size: 14px; background: #e0e0e0; padding: 4px 8px; border-radius: 4px; color: #333;">State: idle</span>
        </div>
      </div>


    </div>
    
    <!-- Polyfill for older browsers -->
    <script type="module" src="/src/index.ts"></script>
    
    <script>
      // 1. Setup Static Waveform
      document.addEventListener('DOMContentLoaded', () => {
        const staticWaveform = document.getElementById('demo-static-waveform');
        // Generate 150 random data points to simulate an audio track
        const mockData = Array.from({length: 150}, () => Math.random() * 0.8 + 0.1);
        staticWaveform.data = mockData;
        
        
        // 2. Setup Live Waveform
        const liveWaveform = document.getElementById('demo-live-waveform');
        const audioElement = document.getElementById('demo-audio-player');
        const processingBtn = document.getElementById('btn-processing');
        
        let audioCtx;
        let analyser;
        let source;
        let isConnected = false;
        
        // We must initialize AudioContext upon first user interaction
        audioElement.addEventListener('play', () => {
          if (!isConnected) {
            // Standard + Safari fallback
            const AudioContextClass = window.AudioContext || window.webkitAudioContext;
            audioCtx = new AudioContextClass();
            analyser = audioCtx.createAnalyser();
            
            // Replicate the ElevenLabs smoothing
            analyser.fftSize = 1024;
            analyser.smoothingTimeConstant = 0.8;
            
            source = audioCtx.createMediaElementSource(audioElement);
            source.connect(analyser);
            analyser.connect(audioCtx.destination);
            
            isConnected = true;
          }
          
          if (audioCtx.state === 'suspended') {
            audioCtx.resume();
          }
          
          // Pass the analyser node to our Lit Component!
          liveWaveform.analyserNode = analyser;
          liveWaveform.active = true;
          liveWaveform.processing = false;
          processingBtn.textContent = 'Toggle "Processing" State';
        });
        
        audioElement.addEventListener('pause', () => {
          // Keep it "active" to show it decaying to zero smoothly, but 
          // practically you might set active = false depending on your UX.
          liveWaveform.active = false;
        });
        
        audioElement.addEventListener('ended', () => {
          liveWaveform.active = false;
        });
        
        // Setup "Processing" toggle button
        processingBtn.addEventListener('click', () => {
          if (!liveWaveform.processing) {
            audioElement.pause();
            liveWaveform.active = false;
            liveWaveform.processing = true;
            processingBtn.textContent = 'Stop "Processing"';
          } else {
            liveWaveform.processing = false;
            processingBtn.textContent = 'Toggle "Processing" State';
          }
        });

        // 3. Setup Audio Player
        const demoPlayer = document.getElementById('demo-player');
        // Setting the property object natively in JS since HTML attributes don't parse JSON nicely
        demoPlayer.item = { id: 'music-1', src: '/samples/music_sample.wav' };
        
        // 4. Setup Voice Button State Cycle
        const voiceBtn = document.getElementById('demo-voice-btn');
        const voiceStateText = document.getElementById('demo-voice-btn-state');
        
        // Share the analyser node from the live demo just to prove it works!
        // In a real app this would come from navigator.mediaDevices.getUserMedia()
        
        const stateCycle = ['idle', 'recording', 'processing', 'success', 'error'];
        let cycleIndex = 0;
        
        voiceBtn.addEventListener('voice-button-click', () => {
           // We cycle to the next state
           cycleIndex = (cycleIndex + 1) % stateCycle.length;
           const newState = stateCycle[cycleIndex];
           
           voiceBtn.state = newState;
           
           // If we enter recording, inject the analyser node so the mini-waveform bounces!
           if (newState === 'recording' && analyser) {
             voiceBtn.analyserNode = analyser;
           } else {
             voiceBtn.analyserNode = undefined;
           }
           
           // Update labels to make the demo pretty
           if (newState === 'idle') voiceBtn.label = 'Start Recording';
           else if (newState === 'recording') voiceBtn.label = 'Stop Recording';
           else if (newState === 'processing') voiceBtn.label = 'Analyzing...';
           else voiceBtn.label = ''; // Hide label for success/error dots
           
           voiceStateText.textContent = `State: ${newState}`;
        });
        
        // We also want to listen for the transient states resolving themselves back to idle
        // The lit component automatically resets state to 'idle' after 1500ms of success/error feedback
        // But we need to sync our demo's label/index state!
        
        // Let's create an observer for the `state` property
        const observer = new MutationObserver((mutations) => {
          mutations.forEach((mutation) => {
            if (mutation.type === 'attributes' && mutation.attributeName === 'state') {
              const currentState = voiceBtn.getAttribute('state');
              if (currentState === 'idle') {
                 cycleIndex = 0;
                 voiceBtn.label = 'Start Recording';
                 voiceStateText.textContent = 'State: idle (auto-reset)';
              }
            }
          });
        });
        observer.observe(voiceBtn, { attributes: true });
        
      });
    </script>
  </body>
</html>